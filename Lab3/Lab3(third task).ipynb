{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c449fa-d707-47bc-805a-02a6dc779133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('test.csv')\n",
    "df['label'] = df['1']\n",
    "df['text'] = df['This model may be ok for sedentary types, but I\\'m active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment!']\n",
    "df = df.drop(['1','mens ultrasheer', 'This model may be ok for sedentary types, but I\\'m active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment!'], axis = 1)\n",
    "df = df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80523af-56b0-4db1-b9ee-568bf8b9a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Art\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Art\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Art\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stopwordf = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  \n",
    "    return text\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000 \n",
    "max_length = 100    \n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdaff15-d856-4836-b63c-f98d09d8e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,341,857\n",
      "Trainable params: 1,341,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_length))  \n",
    "model.add(LSTM(64, return_sequences=True))  \n",
    "model.add(LSTM(32))                      \n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7126f-515a-4aab-ab3e-4380af3086e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 48s 174ms/step - loss: -20.0452 - accuracy: 0.1996 - val_loss: -30.7446 - val_accuracy: 0.1800\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 42s 170ms/step - loss: -37.7608 - accuracy: 0.2004 - val_loss: -47.3021 - val_accuracy: 0.1800\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 44s 177ms/step - loss: -54.2867 - accuracy: 0.2004 - val_loss: -64.6470 - val_accuracy: 0.1800\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 43s 171ms/step - loss: -70.7344 - accuracy: 0.2004 - val_loss: -81.4521 - val_accuracy: 0.1800\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 45s 179ms/step - loss: -86.9184 - accuracy: 0.2004 - val_loss: -98.1010 - val_accuracy: 0.1800\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 44s 174ms/step - loss: -102.9889 - accuracy: 0.2004 - val_loss: -114.6783 - val_accuracy: 0.1800\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 41s 166ms/step - loss: -119.0149 - accuracy: 0.2004 - val_loss: -131.2020 - val_accuracy: 0.1800\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 42s 169ms/step - loss: -135.0147 - accuracy: 0.2004 - val_loss: -147.7119 - val_accuracy: 0.1800\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 42s 168ms/step - loss: -150.9979 - accuracy: 0.2004 - val_loss: -164.1716 - val_accuracy: 0.1800\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 42s 166ms/step - loss: -166.9586 - accuracy: 0.2004 - val_loss: -180.6790 - val_accuracy: 0.1800\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 42s 169ms/step - loss: -182.8911 - accuracy: 0.2004 - val_loss: -197.1060 - val_accuracy: 0.1800\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 42s 167ms/step - loss: -198.8236 - accuracy: 0.2004 - val_loss: -213.5654 - val_accuracy: 0.1800\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 42s 166ms/step - loss: -214.7563 - accuracy: 0.2004 - val_loss: -229.9884 - val_accuracy: 0.1800\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 42s 170ms/step - loss: -230.6932 - accuracy: 0.2004 - val_loss: -246.4746 - val_accuracy: 0.1800\n",
      "Epoch 15/15\n",
      "159/250 [==================>...........] - ETA: 14s - loss: -242.9244 - accuracy: 0.1999"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequences, df['label'], epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92de82-816d-4488-9161-60483c4f636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
